# .github/workflows/retraining_pipeline.yml
name: Automated Model Retraining

on:
  repository_dispatch:
    types: [trigger-retraining]

jobs:
  retrain:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up DVC
        uses: iterative/setup-dvc@v1

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"

      - name: Install Dependencies
        run: pip install -r requirements.txt

      - name: Pull Latest Data with DVC
        run: dvc pull
        env:
          DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}

      - name: Create New Training Dataset
        # Menjalankan skrip untuk menggabungkan data lama dengan log prediksi baru
        run: python combine_data.py # Modifikasi combine_data.py untuk membaca new_prediction_logs.csv

      - name: Run Training Script
        env:
          DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
        run: python train.py --dataset data/combined_data.csv --run_name "Automated Retraining"

      - name: Promote New Model to Production
        env:
          DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
        run: python promote_model.py

      - name: Version the New Combined Data
        run: |
          dvc add data/combined_data.csv
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          git add data/combined_data.csv.dvc .gitignore
          git commit -m "chore: Update training data after automated retraining"
          git push
