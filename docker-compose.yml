services:
  mlflow:
    image: ghcr.io/mlflow/mlflow:v3.1.1
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/mlflow/mlruns
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri sqlite:////mlflow/mlruns/mlflow.db
      --default-artifact-root /mlflow/mlruns
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000"]
      interval: 30s
      timeout: 10s
      retries: 3

  mlflow-serving:
    image: ghcr.io/mlflow/mlflow:v2.11.1
    ports:
      - "8001:8001"
    volumes:
      - ./mlruns:/mlflow/mlruns
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    command: >
      mlflow models serve
      --model-uri "models:/prediksi-penyakit-jantung/2"
      --host 0.0.0.0
      --port 8001
      --enable-mlserver
    depends_on:
      mlflow:
        condition: service_healthy

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml

  grafana:
    image: grafana/grafana-oss:latest
    ports:
      - "3000:3000"
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - prometheus
