services:
  mlflow-server:
    image: ghcr.io/mlflow/mlflow:v2.13.2
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/mlruns
    command: >
      mlflow server
      --host 0.0.0.0
      --port 5000
      --backend-store-uri sqlite:////mlruns/mlflow.db 
      --default-artifact-root file:///mlruns
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000"]
      interval: 30s
      timeout: 10s
      retries: 3

  mlflow-serving:
    image: ghcr.io/mlflow/mlflow:v2.13.2
    ports:
      - "8001:8001"
      - "8081:8081"
    volumes:
      - ./mlruns:/mlruns
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow-server:5000
      - MODEL_URI=models:/HeartDiseaseClassifier/Production
    command: >
      mlflow models serve
      --model-uri "$${MODEL_URI}"
      --host 0.0.0.0
      --port 8001
      --enable-mlserver
    depends_on:
      mlflow-server:
        condition: service_healthy

  gradio-app:
    build:
      context: .
      dockerfile: Dockerfile.app
    ports:
      - "7860:7860"
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow-server:5000
    depends_on:
      - mlflow-server
      - mlflow-serving

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    depends_on:
      - mlflow-serving

  grafana:
    image: grafana/grafana-oss:latest
    ports:
      - "3000:3000"
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
    depends_on:
      - prometheus
